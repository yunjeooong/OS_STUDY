# 26장  — 스레드·병행성 핵심 정리

---

## 1. 왜 병행성(concurrency)인가? ― 시스템 구조 속 필연성

| 환경          | 개념                                    | **왜** 병행성이 필요한가?                                                                               |
| ----------- | ------------------------------------- | ---------------------------------------------------------------------------------------------- |
| **다중프로그래밍** | 단일 CPU가 프로세스를 빠르게 교대(run–switch)하며 실행 | **CPU 효율**: I/O 대기 동안 다른 작업을 돌려 총 처리량을 높임. **반응성**: 각 작업이 조금씩이라도 꾸준히 진행되어 “멈추지 않는” 사용자 경험을 제공. |
| **멀티프로세싱**  | 여러 CPU/코어가 물리적으로 병렬 실행                | **스케일링**: 동일 시간에 더 많은 일을 수행하려면 동시 실행 흐름이 필수. 그러나 각 코어가 동일 메모리를 공유하므로 **데이터 일관성** 문제가 등장.       |
| **분산처리**    | 네트워크로 묶인 머신들이 하나의 작업을 분담              | **고가용성 & 자원 확장성**: 단일 서버 한계를 넘지만, 노드/네트워크 지연·실패로 인해 **동기화·합의** 알고리즘(예: Paxos, Raft)이 요구됨.      |

> **핵심 이유**: 컴퓨팅 자원을 최대 활용하고, I/O 지연을 숨기며, 사용자 체감 응답성을 지키기 위해 OS·언어·라이브러리 모두 병행 실행 메커니즘을 제공한다.

---

## 2. 스레드(Thread)란? ― “가벼운 프로세스” 모델

### 2.1 구조

* **공유**: 코드, 전역・정적 데이터, 힙, 커널 객체(파일 테이블 등)
* **개별**: 프로그램 카운터(PC), 레지스터 집합, **스택 + TLS**. 각 스레드 스택에는 함수 지역변수, 리턴 주소, 예외 프레임 등이 독립적으로 쌓여 **재진입성**을 보장한다.

### 2.2 왜 스레드를 쓰는가?

1. **콘텍스트 스위치 비용 절감** — 주소 공간을 그대로 두고 레지스터·스택만 갈아끼우면 되므로 프로세스 간 전환보다 수 μs 빠르다.
2. **커널 캐시 재사용** — 프로세스 내부의 파일 캐시·페이지 캐시를 공유해 I/O locality가 깨지지 않는다.
3. **자연스러운 비동기화** — 블로킹 I/O 호출이 스레드 단위로 잠들어도 프로세스 전체가 멈추지 않는다.

### 2.3 왜 위험한가?

* **데이터 경쟁** — 메모리를 공유하므로 잘못 접근하면 내용이 뒤섞임.
* **에러 전파** — 하나의 스레드가 잘못된 포인터로 힙을 덮어쓰면 프로세스 전체가 파괴.
* **디버깅 난이도** — 실행 순서가 매 번 달라 재현이 어렵다.

---

## 3. Pthreads 예제와 비결정성(determinism)의 붕괴

```c
void* mythread(void* arg) {
    printf("%s: begin\n", (char*)arg);
    for (int i = 0; i < 1e7; i++) counter++;
    printf("%s:   end\n", (char*)arg);
    return NULL;
}
```

* **어디서 비결정성이 생기나?**

    * `pthread_create()`는 단순 함수 호출이 아니라 **커널 스케줄러**에 등록만 하고 즉시 리턴한다. 실제 실행 시점은 **타이머 인터럽트**나 `sched_yield()` 등 외부 요인에 좌우.
    * 캐시 미스・TLB 미스・I/O 인터럽트 같은 하드웨어 이벤트도 순서를 바꾼다.
* **결과**: `counter`의 최종 값이 20 000 000이 아닐 수 있고, 로그 순서가 A→B 나 B→A 등으로 뒤섞인다.

> **인사이트**: 병행 프로그램은 ‘가능한 모든 실행(schedules)’을 고려해 **올바름(safety) + 전진성(liveness)** 을 증명하거나 테스팅해야 한다.

---

## 4. 경쟁 조건(Race Condition) 해부 ― 어셈블리 레벨 타임라인

아래 한 줄 C 코드가 왜 위험한지 어셈블리로 쪼개본다.

```c
counter = counter + 1;   // (A)
```

| 단계           | Thread 1              | Thread 2              | 메모리의 counter |
| ------------ | --------------------- | --------------------- | ------------ |
| ① Load       | `R1 ← (counter)` (50) | –                     | 50           |
| ② Add        | `R1 ← R1+1` (51)      | –                     | 50           |
| *(컨텍스트 스위치)* |                       |                       |              |
| ③ Load       | –                     | `R2 ← (counter)` (50) | 50           |
| ④ Add        | –                     | `R2 ← 50+1` (51)      | 50           |
| ⑤ Store      | –                     | `(counter) ← R2`      | **51**       |
| *(스위치 복귀)*   |                       |                       |              |
| ⑥ Store      | `(counter) ← R1`      | –                     | **51**       |

* **왜 이런 일이?**

    * CPU는 (A)를 단일 명령처럼 보여주지만 내부에선 *load–add–store* 세 단계로 분리된다.
    * 스케줄러가 두 스레드를 단계 ②↔③ 중간에 교대시키면, 실제 메모리 쓰기(store)는 1회만 이뤄져 총 +1 결과.

> **결론**: “읽기–수정–쓰기” 시퀀스를 **원자성(atomicity)** 으로 감싸야 안전하다.

---

## 5. 용어 & 개념 맵 

| 용어                         | 정의                         | **왜 중요한가?**                       |
| -------------------------- | -------------------------- | --------------------------------- |
| **임계영역(Critical Section)** | 공유 데이터를 읽거나 수정하는 코드 블록     | 동시 실행 시 가장 취약; 보호 대상 지정이 문제의 시작점  |
| **상호배제(Mutual Exclusion)** | 임계영역에 한 번에 하나의 스레드만 들어감    | 경쟁 조건을 *근본적으로* 차단하는 최소 조건         |
| **데드락(Deadlock)**          | 두 자원이 서로를 기다려 영원 정지        | 시스템 멈춤 → 가용성(liveness) 위반, 복구 어렵다 |
| **라이브락(Livelock)**         | 락을 서로 양보 → 활발히 실행되지만 진전 없음 | CPU 100%로도 결과 미도달 → 감지 난이도 높음     |
| **기아(Starvation)**         | 특정 스레드가 락/CPU를 계속 얻지 못함    | 우선순위 역전, 응답시간 폭증 등 실시간 시스템 치명     |

---

## 6. 상호배제 구현 스펙트럼 

| 계층             | 대표 기법                              | 장점                         | 단점/주의                        | **언제 쓰나?**              |
| -------------- | ---------------------------------- | -------------------------- | ---------------------------- | ----------------------- |
| **소프트웨어 알고리즘** | Peterson, Dekker                   | 하드웨어 특수 명령 필요 없음           | Busy‑wait → CPU 낭비, 다코어 확장성↓ | 교육, 단일‑코어 오래된 임베디드      |
| **커널 기법**      | CLI/STI (인터럽트 off/on)              | 아주 짧은 구간에선 간단·효과적          | SMP에선 모든 코어 정지 → 지연 큼        | 커널 내부 스핀락, BIOS 단일코어 구간 |
| **하드웨어 원자 연산** | `test‑and‑set`, `compare‑and‑swap` | 짧은 락 획득을 CPU 한 사이클로        | 버스 lock 경쟁, 캐시 라인 thrash     | 멀티코어 사용자 공간 스핀락         |
| **고수준 동기화**    | mutex, semaphore, monitor, rw‑lock | 잠자기/깨우기 지원 → CPU 절약, 코드 간결 | 시스템 호출 비용, 우선순위 역전 대응 필요     | 대부분의 사용자·커널 모듈          |

> **선택 법칙**: 임계영역 길이 ≤ 수백 사이클 → 스핀, 그 이상 또는 I/O 포함 → 블로킹(lock + sleep). 스핀 후 한계시간 지나면 커널로 진입해 잠자기 하는 *혼합 어댑티브 락*이 최신 OS 기본.

---

## 7. OS 레벨 관점 체크리스트 (왜 OS가 관여?)

1. **스케줄링** – 공정성 vs 실시간 제약, 우선순위 역전 해결(예: Priority Inheritance) 필요.
2. **락 추적 & 디버깅 지원** – 커널은 락 의존 그래프를 수집해 deadlock detector에 활용한다.
3. **메모리 보호** – 잘못된 스레드가 다른 스레드 스택/TCB 침범 못 하도록 가드 페이지 삽입.
4. **원자 연산 API 노출** – 사용자 공간이 CAS 등을 직접 호출할 수 있게 `libc`, `std::atomic` 제공.

---

## 8. 기타

* **OSTEP.x86** 시뮬레이터로 인터럽트 빈도(random seed) 조정 → 다양한 schedule 재현, 버그 유도.
* `valgrind --tool=helgrind`, `ThreadSanitizer` 로 데이터 레이스 자동 탐지.
* `volatile` 은 재정렬 방지이지 **원자성 보장 수단이 아님** → 반드시 락과 함께.

---

## 9. 정리

> 스레드 = *공유 주소공간* + *독립 실행흐름* ➜ 효율↑ but **데이터 경쟁·데드락** 위험.
>
> 올바름 제외 어떤 최적화도 무의미하다. — *Dijkstra*

